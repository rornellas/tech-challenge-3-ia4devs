# Fine-tuning de Modelos de Linguagem com Python e Jupyter

### Grupo 38
- Pedro Vianna Silveira
- Rafael Silva Souza
- Rodrigo de Freitas Ornellas

---

### üîó Reposit√≥rio do C√≥digo

[\[Link para o reposit√≥rio GitHub\]](https://github.dev/rornellas/tech-challenge-3-ia4devs)

---

## 1. Introdu√ß√£o

#### Contexto e Motiva√ß√£o
Neste projeto, buscamos explorar o processo de **fine-tuning** em um **modelo de linguagem de grande escala (LLM)**, utilizando Python e Jupyter como ferramentas principais. Nosso foco est√° na adapta√ß√£o do modelo a um dataset espec√≠fico para aprimorar a capacidade de gerar respostas adequadas com base em descri√ß√µes de produtos. Isso reflete um cen√°rio real, no qual plataformas de e-commerce se beneficiam ao melhorar a intera√ß√£o com os usu√°rios atrav√©s de respostas mais precisas e contextualizadas.

#### Objetivos do Projeto
O projeto tem tr√™s metas principais:
1. Realizar o fine-tuning de um modelo de linguagem pr√©-treinado, especificamente o **unsloth/mistral-7b-instruct-v0.3-bnb-4bit**.
2. Avaliar a evolu√ß√£o do modelo ap√≥s o fine-tuning, comparando com sua vers√£o original.
3. Documentar detalhadamente o processo de ajuste fino, abordando os desafios e solu√ß√µes encontradas.

---

## 2. Descri√ß√£o do Problema

- **Problema**: Como adaptar um modelo de linguagem para responder perguntas a partir de descri√ß√µes de produtos, utilizando um dataset espec√≠fico? O objetivo √© criar um sistema que compreenda melhor essas intera√ß√µes textuais e gere respostas √∫teis e relevantes.
- **Relev√¢ncia**: Plataformas de e-commerce se beneficiam ao fornecer respostas r√°pidas e precisas √†s perguntas dos usu√°rios, melhorando a experi√™ncia de compra. Um modelo ajustado √†s descri√ß√µes de produtos √© um passo essencial para alcan√ßar esse objetivo.

---

## 3. Fundamenta√ß√£o Te√≥rica

- **Modelos de Linguagem (Foundation Models)**: Usamos o **unsloth/mistral-7b-instruct-v0.3-bnb-4bit**, que serve como base para o ajuste fino.
- **Fine-tuning**: Processo de especializa√ß√£o de um modelo pr√©-treinado em uma nova tarefa espec√≠fica.
- **Pr√©-processamento**: Realizamos a normaliza√ß√£o de texto, incluindo decodifica√ß√£o de HTML (para lidar com texto codificado em ASCII).
- **Treinamento Supervisionado (SFT)**: T√©cnica utilizada para ajustar o modelo, fornecendo exemplos de entradas e sa√≠das.

---

## 4. Metodologia

- **Ambiente de Desenvolvimento**: O projeto foi desenvolvido no **Google Colab** com suporte a GPU, garantindo efici√™ncia durante o treinamento do modelo.
- **Prepara√ß√£o dos Dados**: Usamos a biblioteca `pandas` para manipula√ß√£o e pr√©-processamento do dataset, incluindo normaliza√ß√£o e limpeza dos textos.
- **Sele√ß√£o e Configura√ß√£o do Modelo**: Implementamos o modelo **Mistral** utilizando a biblioteca `transformers`, ajustando as entradas com tokeniza√ß√£o adequada.
- **Execu√ß√£o do Fine-tuning**: O processo de fine-tuning foi realizado com o **SFTTrainer** da biblioteca `trl`, que nos permitiu parametrizar o ajuste fino de maneira eficiente.
- **Avalia√ß√£o e Valida√ß√£o**: Testamos o modelo fine-tunado e comparamos seus resultados com o desempenho original, identificando ganhos significativos.

---

## 5. Implementa√ß√£o

- **Ferramentas e Bibliotecas Utilizadas**: 
  - **Google Colab**: Ambiente de desenvolvimento com GPU.
  - **Transformers e datasets**: Para manipula√ß√£o e treinamento de modelos pr√©-treinados.
  - **Torch**: Base para as opera√ß√µes de deep learning.
  - **TRL**: Utilizada para treinamento supervisionado do modelo.
  - **Unsloth**: Implementa√ß√£o do modelo `unsloth/mistral`.
  - **Pandas** e **nltk**: Manipula√ß√£o de dados e processamento textual.
  
- **Carregamento e Limpeza de Dados**: Utilizamos scripts personalizados para carregar e processar o dataset, com limpeza, normaliza√ß√£o e exclus√£o de stopwords, preparando o conjunto para o treinamento.
  
- **Fine-tuning do Modelo**: O ajuste fino foi realizado com o `SFTTrainer`, onde utilizamos dados de entrada e sa√≠da espec√≠ficos para treinar o modelo de forma supervisionada.

- **Gera√ß√£o de Respostas**: Implementamos uma fun√ß√£o para gerar respostas automatizadas com base nas perguntas dos usu√°rios e nas descri√ß√µes dos produtos dispon√≠veis no dataset.

---

## 6. Resultados

- **Compara√ß√£o de Desempenho**: Ao comparar o modelo pr√©-treinado com a vers√£o fine-tunada, observamos uma melhoria significativa na capacidade do modelo em fornecer respostas mais coerentes e ajustadas ao contexto das perguntas.
  
- **Avalia√ß√£o Qualitativa**: A an√°lise qualitativa das respostas geradas pelo modelo treinado demonstrou que o fine-tuning ajudou o modelo a compreender melhor a rela√ß√£o entre as perguntas e as descri√ß√µes dos produtos.

---

## 7. Conclus√£o

- **Resultados Principais**: O fine-tuning trouxe melhorias substanciais ao desempenho do modelo, tornando-o mais adequado para a tarefa espec√≠fica de responder perguntas baseadas em descri√ß√µes de produtos.
  
- **Limita√ß√µes e Desafios**: Enfrentamos alguns desafios durante o pr√©-processamento dos dados e na parametriza√ß√£o do modelo, mas esses problemas foram contornados com ajustes t√©cnicos e melhorias no pipeline de dados.
  
- **Pr√≥ximos Passos**: Futuras melhorias podem incluir a utiliza√ß√£o de modelos maiores ou o uso de t√©cnicas de data augmentation para melhorar a diversidade e representatividade dos dados
